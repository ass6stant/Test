{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>11432.089844</td>\n",
       "      <td>11759.959961</td>\n",
       "      <td>11388.040039</td>\n",
       "      <td>11734.320312</td>\n",
       "      <td>212830000</td>\n",
       "      <td>11734.320312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>11729.669922</td>\n",
       "      <td>11867.110352</td>\n",
       "      <td>11675.530273</td>\n",
       "      <td>11782.349609</td>\n",
       "      <td>183190000</td>\n",
       "      <td>11782.349609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>11781.700195</td>\n",
       "      <td>11782.349609</td>\n",
       "      <td>11601.519531</td>\n",
       "      <td>11642.469727</td>\n",
       "      <td>173590000</td>\n",
       "      <td>11642.469727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>11632.809570</td>\n",
       "      <td>11633.780273</td>\n",
       "      <td>11453.339844</td>\n",
       "      <td>11532.959961</td>\n",
       "      <td>182550000</td>\n",
       "      <td>11532.959961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>11532.070312</td>\n",
       "      <td>11718.280273</td>\n",
       "      <td>11450.889648</td>\n",
       "      <td>11615.929688</td>\n",
       "      <td>159790000</td>\n",
       "      <td>11615.929688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date          Open          High           Low         Close  \\\n",
       "0  2008-08-08  11432.089844  11759.959961  11388.040039  11734.320312   \n",
       "1  2008-08-11  11729.669922  11867.110352  11675.530273  11782.349609   \n",
       "2  2008-08-12  11781.700195  11782.349609  11601.519531  11642.469727   \n",
       "3  2008-08-13  11632.809570  11633.780273  11453.339844  11532.959961   \n",
       "4  2008-08-14  11532.070312  11718.280273  11450.889648  11615.929688   \n",
       "\n",
       "      Volume     Adj Close  \n",
       "0  212830000  11734.320312  \n",
       "1  183190000  11782.349609  \n",
       "2  173590000  11642.469727  \n",
       "3  182550000  11532.959961  \n",
       "4  159790000  11615.929688  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#Load datas\n",
    "df_DJIA = pd.read_csv('data/DJIA_table.csv').iloc[::-1]#Dow Jones indust Avg daily infos\n",
    "df_DJIA.index = range(df_DJIA.shape[0])\n",
    "\n",
    "df_News = pd.read_csv('data/Combined_News_DJIA.csv') # Top 25 news\n",
    "\n",
    "df_News = pd.concat((df_News.iloc[:, 0:2],df_News.iloc[:, 2:].astype(str)), axis = 1)\n",
    "# Visualization\n",
    "#df_News.head()\n",
    "#df_DJIA.head()\n",
    "#df_News.head()\n",
    "\n",
    "#Drop the first line in order to have the same size than all future labels\n",
    "df_News = df_News.drop([0])\n",
    "df_News.index = range(df_News.shape[0])\n",
    "df_DJIA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of labels\n",
    "\n",
    "## Price variation analysis \n",
    "\n",
    "\n",
    "<b>Label 1: </b> Given label of the dataset, corresponding to the evolution of the price for the day (1: increased, 0: decreased) <br>\n",
    "\n",
    "<b>Label 2: </b> Also a price variation label, but this time we only look for a variation with a given threshold (0: Price varied less than the threshold, 1: more) <br>\n",
    "    \n",
    "## Volume variation analysis    \n",
    "\n",
    "    \n",
    "<b> Label 3: </b> 3 classes: (0: decrease, 1: Stagnates, 2: Increased), with threshold  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label1 = Fluctuation of price (with threshold)\n",
    "# Label : 2 = Stagnates\n",
    "\n",
    "P = df_DJIA['Adj Close']\n",
    "V = df_DJIA['Volume']\n",
    "\n",
    "delta_P = [] # List filled with price variation\n",
    "delta_V = [] # List filled with volume variation \n",
    "\n",
    "\n",
    "for i in range(1, df_DJIA.shape[0]): #Fill the lists\n",
    "    delta_P.append(abs((P[i]-P[i-1])/P[i-1]))\n",
    "    delta_V.append((V[i]-V[i-1])/V[i-1])\n",
    "    \n",
    "    \n",
    "#Initiate a np.array for the new labels values\n",
    "label2_val = np.empty([len(delta_P), 3]) # Price variation (abs)\n",
    "label3_val = np.empty([len(delta_V), 3]) # Volume variation\n",
    "\n",
    "#Threshold initialization\n",
    "threshold_P = [0.005, 0.01, 0.02]\n",
    "threshold_V = [0.005, 0.01, 0.02]\n",
    "for j in range(3):\n",
    "    \n",
    "    for i in range(len(delta_P)):\n",
    "        if delta_P[i] > threshold_P[j]:\n",
    "            label2_val[i][j] = 1\n",
    "        else:\n",
    "            label2_val[i][j] = 0\n",
    "        \n",
    "        if delta_V[i] > threshold_V[j]:\n",
    "            label3_val[i][j] = 1\n",
    "        elif delta_V[i] < -threshold_V[j]:\n",
    "            label3_val[i][j] = -1\n",
    "        else:\n",
    "            label3_val[i][j] = 0\n",
    "        \n",
    "        \n",
    "\n",
    "df_Label2 = pd.DataFrame(label2_val) \n",
    "df_Label2.columns = ['2 T = ' +str(x) for x in threshold_P]\n",
    "\n",
    "df_Label3 = pd.DataFrame(label3_val)\n",
    "df_Label3.columns = ['3 T = ' + str(y) for y in threshold_V]\n",
    "\n",
    "df_News = pd.concat((df_News.iloc[:, 0:2], df_Label2, df_Label3 ,df_News.iloc[:, 2:].astype(str)), axis = 1)\n",
    "\n",
    "#df_News.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004093061696201033"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_P[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Creation of our features with a sentiment analysis, with the library vaderSentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "\n",
    "# Creates a numpy array with the values of the SA (negativity, neutrality, compound)#\n",
    "# for each of the Top25 headlines for each day                                      #\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer() #Sentiment analyzer\n",
    "threshold_c = 0.5 # Compound threshold\n",
    "\n",
    "#DataFrame initialization\n",
    "df_Sentiments = df_News\n",
    "df_Sent_Full = np.empty([df_News.shape[0],(df_News.shape[1]-8)*3+8])\n",
    "for i in range(df_News.shape[0]): #Fills the array\n",
    "    for j in range(df_News.shape[1]):\n",
    "        if j >= 8:\n",
    "            score =  analyzer.polarity_scores(df_News.iloc[i,j]) #result of sentiment analysis (dictionary format) \n",
    "            df_Sent_Full[i][8 +(j-8)*3] = score['pos']\n",
    "            df_Sent_Full[i][9 +(j-8)*3] = score['neu']\n",
    "            df_Sent_Full[i][10 +(j-8)*3]= score['compound']\n",
    "            \n",
    "            if  score['pos'] > score['neg'] and score['compound'] >= threshold_c :\n",
    "                df_Sentiments.iloc[i,j] = 1\n",
    "            elif score['neg'] > score['pos'] and score['compound'] <= threshold_c:\n",
    "                df_Sentiments.iloc[i,j] = -1\n",
    "            else:\n",
    "                df_Sentiments.iloc[i,j] = 0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H 1 POS</th>\n",
       "      <th>H 1 NEU</th>\n",
       "      <th>H 1 COM</th>\n",
       "      <th>H 2 POS</th>\n",
       "      <th>H 2 NEU</th>\n",
       "      <th>H 2 COM</th>\n",
       "      <th>H 3 POS</th>\n",
       "      <th>H 3 NEU</th>\n",
       "      <th>H 3 COM</th>\n",
       "      <th>H 4 POS</th>\n",
       "      <th>...</th>\n",
       "      <th>H 22 COM</th>\n",
       "      <th>H 23 POS</th>\n",
       "      <th>H 23 NEU</th>\n",
       "      <th>H 23 COM</th>\n",
       "      <th>H 24 POS</th>\n",
       "      <th>H 24 NEU</th>\n",
       "      <th>H 24 COM</th>\n",
       "      <th>H 25 POS</th>\n",
       "      <th>H 25 NEU</th>\n",
       "      <th>H 25 COM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.332</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.8156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.723</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.753</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-0.1832</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.175</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.503</td>\n",
       "      <td>-0.7845</td>\n",
       "      <td>0.102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.538</td>\n",
       "      <td>-0.7184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.751</td>\n",
       "      <td>-0.8074</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.508</td>\n",
       "      <td>-0.6369</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.598</td>\n",
       "      <td>-0.5719</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.823</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.806</td>\n",
       "      <td>-0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.184</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.6908</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.7096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.671</td>\n",
       "      <td>-0.7481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7096</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.737</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   H 1 POS  H 1 NEU  H 1 COM  H 2 POS  H 2 NEU  H 2 COM  H 3 POS  H 3 NEU  \\\n",
       "0    0.332    0.668   0.8156      0.0    0.723  -0.3182    0.225    0.775   \n",
       "1    0.175    0.656   0.0258      0.0    1.000   0.0000    0.000    0.503   \n",
       "2    0.000    0.538  -0.7184      0.0    0.751  -0.8074    0.110    0.508   \n",
       "3    0.184    0.816   0.2023      0.0    1.000   0.0000    0.384    0.616   \n",
       "4    0.000    0.671  -0.7481      0.0    1.000   0.0000    0.178    0.667   \n",
       "\n",
       "   H 3 COM  H 4 POS    ...     H 22 COM  H 23 POS  H 23 NEU  H 23 COM  \\\n",
       "0   0.4404    0.149    ...       0.0000     0.000     0.753   -0.3182   \n",
       "1  -0.7845    0.102    ...       0.5267     0.140     0.785    0.3818   \n",
       "2  -0.6369    0.000    ...       0.4939     0.000     0.598   -0.5719   \n",
       "3   0.6808    0.000    ...      -0.5994     0.248     0.571    0.1779   \n",
       "4   0.4215    0.132    ...      -0.7096     0.000     0.737   -0.3612   \n",
       "\n",
       "   H 24 POS  H 24 NEU  H 24 COM  H 25 POS  H 25 NEU  H 25 COM  \n",
       "0     0.263     0.414   -0.1832     0.000     1.000    0.0000  \n",
       "1     0.000     1.000    0.0000     0.000     1.000    0.0000  \n",
       "2     0.000     0.823   -0.4215     0.000     0.806   -0.3400  \n",
       "3     0.000     0.427   -0.6908     0.349     0.651    0.7096  \n",
       "4     0.000     1.000    0.0000     0.000     1.000    0.0000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = []\n",
    "colnames = list(df_News.columns.values[0:8])\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "        colnames.append('H ' + str(i+1) + ' POS')\n",
    "        colnames.append('H ' + str(i+1) + ' NEU')\n",
    "        colnames.append('H ' + str(i+1) + ' COM')\n",
    "\n",
    "\n",
    "df_Sentiment_Full = pd.DataFrame(data = df_Sent_Full, columns = colnames)\n",
    "\n",
    "df_Sentiment_Full = pd.concat((df_News.iloc[:,:8],df_Sentiment_Full.iloc[:,8:]), axis = 1)\n",
    "df_Sentiment_Full.iloc[:,8:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = df_Sentiment_Full.iloc[:, 1]\n",
    "X = df_Sentiment_Full.iloc[:, 8:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "clf = PCA(n_components = 50)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "X_pca=clf.transform(X)\n",
    "\n",
    "data = [i for i in range(1,51)]\n",
    "values = clf.explained_variance_ratio_.cumsum()\n",
    "\n",
    "plt.plot(data, values)\n",
    "plt.title('PCA explained variance')\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "           Initial Sentiments           \n",
      "============================================================\n",
      "===============  Label 1  =============== \n",
      " 0.5025125628140703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.34      0.37       264\n",
      "           1       0.55      0.63      0.59       333\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       597\n",
      "   macro avg       0.48      0.49      0.48       597\n",
      "weighted avg       0.49      0.50      0.49       597\n",
      "\n",
      "===============  Label 2, threshold 0.005 =============== \n",
      " 0.5269607843137255\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.51      0.43       146\n",
      "           1       0.66      0.54      0.59       262\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       408\n",
      "   macro avg       0.52      0.52      0.51       408\n",
      "weighted avg       0.56      0.53      0.54       408\n",
      "\n",
      "===============  Label 2, threshold 0.01 =============== \n",
      " 0.6590909090909091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.01      0.25      0.03         4\n",
      "         1.0       0.98      0.67      0.79       216\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       220\n",
      "   macro avg       0.50      0.46      0.41       220\n",
      "weighted avg       0.96      0.66      0.78       220\n",
      "\n",
      "===============  Label 2, threshold 0.02 =============== \n",
      " 0.5507246376811594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.88      0.59      0.71        64\n",
      "\n",
      "   micro avg       0.55      0.55      0.55        69\n",
      "   macro avg       0.44      0.30      0.36        69\n",
      "weighted avg       0.82      0.55      0.66        69\n",
      "\n",
      "===============  Label 3, threshold  0.005 =============== \n",
      " 0.7085427135678392\n",
      "===============  Label 3, threshold  0.01 =============== \n",
      " 0.71160409556314\n",
      "===============  Label 3, threshold  0.02 =============== \n",
      " 0.6436170212765957\n",
      "\n",
      " ============================================================\n",
      "           New Features           \n",
      "============================================================\n",
      "===============  Label 1  =============== \n",
      " 0.48576214405360135\n",
      "===============  Label 2, threshold 0.005 =============== \n",
      " 0.49754901960784315\n",
      "===============  Label 2, threshold 0.01 =============== \n",
      " 0.5954545454545455\n",
      "===============  Label 2, threshold 0.02 =============== \n",
      " 0.5797101449275363\n",
      "===============  Label 3, threshold  0.005 =============== \n",
      " 0.6716917922948074\n",
      "===============  Label 3, threshold  0.01 =============== \n",
      " 0.71160409556314\n",
      "===============  Label 3, threshold  0.02 =============== \n",
      " 0.6205673758865248\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "results_RF = []\n",
    "results_RF_new_feat = []\n",
    "\n",
    "########################################################\n",
    "# Initial Sentiments\n",
    "########################################################\n",
    "\n",
    "print(20*'===')\n",
    "print(10*' ', 'Initial Sentiments', 10*' ')\n",
    "print(20*'===')\n",
    "\n",
    "##############\n",
    "#Label 1\n",
    "##############\n",
    "y = df_Sentiment_Full.iloc[:, 1]\n",
    "X = df_Sentiment_Full.iloc[:, 8:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(5*'===',' Label 1 ', 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "results_RF.append(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test,y_pred))\n",
    "\n",
    "##############\n",
    "#Label 2\n",
    "##############\n",
    "\n",
    "\n",
    "#Deal wih imbalance\n",
    "for i in range(3):\n",
    "    \n",
    "    df_label2_1= df_Sentiment_Full.sort_values(['2 T = ' + str(threshold_P[i])], ascending = False)\n",
    "    n_pos = df_label2_1.loc[df_label2_1['2 T = ' + str(threshold_P[i])] == 1].shape[0]\n",
    "    df_label2_1 = pd.concat((df_label2_1.iloc[:n_pos, :],df_label2_1.iloc[df_label2_1.shape[0]-n_pos:, :] ))\n",
    "\n",
    "\n",
    "    y = df_label2_1.iloc[:, i+1]\n",
    "    X = df_label2_1.iloc[:, 8:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators = 100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(5*'===',' Label 2, threshold', str(threshold_P[i]) , 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "    results_RF.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.classification_report(y_pred,y_test))\n",
    "    \n",
    "##############\n",
    "#Label 3\n",
    "##############\n",
    "\n",
    "\n",
    "#Deal wih imbalance\n",
    "for i in range(3):\n",
    "    df_label3_1 = df_Sentiment_Full.sort_values(['3 T = ' + str(threshold_V[i])])\n",
    "    n = df_label3_1.loc[df_label3_1['3 T = ' + str(threshold_V[i])] == -1].shape[0]\n",
    "    df_label3_1 = pd.concat((df_label3_1.iloc[:n, :],df_label3_1.iloc[n +1:2*n, :] ,df_label3_1.iloc[df_label3_1.shape[0]-n:, :] ))\n",
    "\n",
    "\n",
    "    y = df_label3_1.iloc[:, 5+i]\n",
    "    X = df_label3_1.iloc[:, 8:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators = 100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(5*'===',' Label 3, threshold ', str(threshold_V[i]), 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "    results_RF.append(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "########################################################\n",
    "# New features\n",
    "########################################################\n",
    "\n",
    "print('\\n', 20*'===')\n",
    "print(10*' ', 'New Features', 10*' ')\n",
    "print(20*'===')\n",
    "\n",
    "##############\n",
    "#Label 1\n",
    "##############\n",
    "y = df_Sentiments.iloc[:, 1]\n",
    "X = df_Sentiments.iloc[:, 8:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(5*'===',' Label 1 ', 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "results_RF_new_feat.append(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "##############\n",
    "#Label 2\n",
    "##############\n",
    "\n",
    "\n",
    "#Deal wih imbalance\n",
    "for i in range(3):\n",
    "    \n",
    "    df_label2_1= df_Sentiments.sort_values(['2 T = ' + str(threshold_P[i])], ascending = False)\n",
    "    n_pos = df_label2_1.loc[df_label2_1['2 T = ' + str(threshold_P[i])] == 1].shape[0]\n",
    "    df_label2_1 = pd.concat((df_label2_1.iloc[:n_pos, :],df_label2_1.iloc[df_label2_1.shape[0]-n_pos:, :] ))\n",
    "\n",
    "\n",
    "    y = df_label2_1.iloc[:, 1+i]\n",
    "    X = df_label2_1.iloc[:, 8:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators = 100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(5*'===',' Label 2, threshold', str(threshold_P[i]) , 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "    results_RF_new_feat.append(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "##############\n",
    "#Label 3\n",
    "##############\n",
    "\n",
    "\n",
    "#Deal wih imbalance\n",
    "for i in range(3):\n",
    "    df_label3_1 = df_Sentiments.sort_values(['3 T = ' + str(threshold_V[i])])\n",
    "    n = df_label3_1.loc[df_label3_1['3 T = ' + str(threshold_V[i])] == -1].shape[0]\n",
    "    df_label3_1 = pd.concat((df_label3_1.iloc[:n, :],df_label3_1.iloc[n +1:2*n, :] ,df_label3_1.iloc[df_label3_1.shape[0]-n:, :] ))\n",
    "\n",
    "\n",
    "    y = df_label3_1.iloc[:, 5+i]\n",
    "    X = df_label3_1.iloc[:, 8:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators = 100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(5*'===',' Label 3, threshold ', str(threshold_V[i]), 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "    results_RF_new_feat.append(metrics.accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "           Initial Sentiments           \n",
      "============================================================\n",
      "===============  Label 1  =============== \n",
      " 0.5050251256281407\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.42      0.25        76\n",
      "           1       0.79      0.52      0.63       322\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       398\n",
      "   macro avg       0.48      0.47      0.44       398\n",
      "weighted avg       0.67      0.51      0.56       398\n",
      "\n",
      "===============  Label 2, threshold 0.005 =============== \n",
      " 0.5367647058823529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.45      0.33       103\n",
      "           1       0.75      0.57      0.65       305\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       408\n",
      "   macro avg       0.51      0.51      0.49       408\n",
      "weighted avg       0.63      0.54      0.57       408\n",
      "\n",
      "(585, 75) (585, 75)\n",
      "===============  Label 2, threshold 0.01 =============== \n",
      " 0.6909090909090909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.69      0.82       220\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       220\n",
      "   macro avg       0.50      0.35      0.41       220\n",
      "weighted avg       1.00      0.69      0.82       220\n",
      "\n",
      "(550, 75) (550, 75)\n",
      "===============  Label 2, threshold 0.02 =============== \n",
      " 0.6086956521739131\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.61      0.76        69\n",
      "\n",
      "   micro avg       0.61      0.61      0.61        69\n",
      "   macro avg       0.50      0.30      0.38        69\n",
      "weighted avg       1.00      0.61      0.76        69\n",
      "\n",
      "(212, 75) (212, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexandre/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/alexandre/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============  Label 3, threshold  0.005 =============== \n",
      " 0.661641541038526\n",
      "===============  Label 3, threshold  0.01 =============== \n",
      " 0.6791808873720137\n",
      "===============  Label 3, threshold  0.02 =============== \n",
      " 0.625886524822695\n",
      "\n",
      " ============================================================\n",
      "           New Features           \n",
      "============================================================\n",
      "===============  Label 1  =============== \n",
      " 0.5251256281407035\n",
      "===============  Label 2, threshold 0.005 =============== \n",
      " 0.5465686274509803\n",
      "===============  Label 2, threshold 0.01 =============== \n",
      " 0.6681818181818182\n",
      "===============  Label 2, threshold 0.02 =============== \n",
      " 0.5507246376811594\n",
      "===============  Label 3, threshold  0.005 =============== \n",
      " 0.6365159128978225\n",
      "===============  Label 3, threshold  0.01 =============== \n",
      " 0.6552901023890785\n",
      "===============  Label 3, threshold  0.02 =============== \n",
      " 0.624113475177305\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "########################################################\n",
    "# Initial Sentiments\n",
    "########################################################\n",
    "results_SVM = []\n",
    "results_SVM_new_feat = []\n",
    "test_size = 0.2\n",
    "gamma = 0.5\n",
    "\n",
    "print(20*'===')\n",
    "print(10*' ', 'Initial Sentiments', 10*' ')\n",
    "print(20*'===')\n",
    "\n",
    "##############\n",
    "#Label 1\n",
    "##############\n",
    "y = df_Sentiment_Full.iloc[:, 1]\n",
    "X = df_Sentiment_Full.iloc[:, 8:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "\n",
    "clf = svm.SVC(gamma = gamma)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(5*'===',' Label 1 ', 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "results_SVM.append(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_pred, y_test))\n",
    "\n",
    "##############\n",
    "#Label 2\n",
    "##############\n",
    "\n",
    "\n",
    "#Deal wih imbalance\n",
    "for i in range(3):\n",
    "    \n",
    "    df_label2_1= df_Sentiment_Full.sort_values(['2 T = ' + str(threshold_P[i])], ascending = False)\n",
    "    n_pos = df_label2_1.loc[df_label2_1['2 T = ' + str(threshold_P[i])] == 1].shape[0]\n",
    "    df_label2_1 = pd.concat((df_label2_1.iloc[:n_pos, :],df_label2_1.iloc[df_label2_1.shape[0]-n_pos:, :] ))\n",
    "    \n",
    "\n",
    "    y = df_label2_1.iloc[:, i+1]\n",
    "    X = df_label2_1.iloc[:, 8:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "\n",
    "\n",
    "    clf = svm.SVC(gamma = gamma)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(5*'===',' Label 2, threshold', str(threshold_P[i]) , 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "    results_SVM.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    if i >= 0:\n",
    "        print(metrics.classification_report(y_pred, y_test))\n",
    "        print(X.loc[df_Sentiment_Full['2 T = 0.01']== 1].shape,X.loc[df_Sentiment_Full['2 T = 0.01']== 1].shape )\n",
    "\n",
    "###################\n",
    "#Label 3          #\n",
    "###################\n",
    "\n",
    "\n",
    "\n",
    "#Deal wih imbalance\n",
    "for i in range(3):\n",
    "    df_label3_1 = df_Sentiment_Full.sort_values(['3 T = ' + str(threshold_V[i])])\n",
    "    n = df_label3_1.loc[df_label3_1['3 T = ' + str(threshold_V[i])] == -1].shape[0]\n",
    "    df_label3_1 = pd.concat((df_label3_1.iloc[:n, :],df_label3_1.iloc[n +1:2*n, :] ,df_label3_1.iloc[df_label3_1.shape[0]-n:, :] ))\n",
    "\n",
    "\n",
    "    y = df_label3_1.iloc[:, i+5]\n",
    "    X = df_label3_1.iloc[:, 8:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "    \n",
    "    \n",
    "    clf = svm.SVC(gamma = gamma)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(5*'===',' Label 3, threshold ', str(threshold_V[i]), 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "    results_SVM.append(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "########################################################\n",
    "# New features\n",
    "########################################################\n",
    "\n",
    "print('\\n', 20*'===')\n",
    "print(10*' ', 'New Features', 10*' ')\n",
    "print(20*'===')\n",
    "\n",
    "##############\n",
    "#Label 1\n",
    "##############\n",
    "y = df_Sentiments.iloc[:, 1]\n",
    "X = df_Sentiments.iloc[:, 8:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "\n",
    "clf = svm.SVC(gamma = gamma)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(5*'===',' Label 1 ', 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "results_SVM_new_feat.append(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "##############\n",
    "#Label 2\n",
    "##############\n",
    "\n",
    "\n",
    "#Deal wih imbalance\n",
    "for i in range(3):\n",
    "    \n",
    "    df_label2_1= df_Sentiments.sort_values(['2 T = ' + str(threshold_P[i])], ascending = False)\n",
    "    n_pos = df_label2_1.loc[df_label2_1['2 T = ' + str(threshold_P[i])] == 1].shape[0]\n",
    "    df_label2_1 = pd.concat((df_label2_1.iloc[:n_pos, :],df_label2_1.iloc[df_label2_1.shape[0]-n_pos:, :] ))\n",
    "\n",
    "\n",
    "    y = df_label2_1.iloc[:, i+1]\n",
    "    X = df_label2_1.iloc[:, 8:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "\n",
    "    clf = svm.SVC(gamma = gamma)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(5*'===',' Label 2, threshold', str(threshold_P[i]) , 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "    results_SVM_new_feat.append(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "##############\n",
    "#Label 3\n",
    "##############\n",
    "\n",
    "\n",
    "#Deal wih imbalance\n",
    "for i in range(3):\n",
    "    df_label3_1 = df_Sentiments.sort_values(['3 T = ' + str(threshold_V[i])])\n",
    "    n = df_label3_1.loc[df_label3_1['3 T = ' + str(threshold_V[i])] == -1].shape[0]\n",
    "    df_label3_1 = pd.concat((df_label3_1.iloc[:n, :],df_label3_1.iloc[n +1:2*n, :] ,df_label3_1.iloc[df_label3_1.shape[0]-n:, :] ))\n",
    "\n",
    "\n",
    "    y = df_label3_1.iloc[:, i+5]\n",
    "    X = df_label3_1.iloc[:, 8:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "    \n",
    "    clf = svm.SVC(gamma = gamma)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(5*'===',' Label 3, threshold ', str(threshold_V[i]), 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "    results_SVM_new_feat.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>Top9</th>\n",
       "      <th>Top10</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Top1  Top2  Top3  Top4  Top5  Top6  Top7  Top8  Top9  Top10  ...    Top16  \\\n",
       "0     1    -1     0    -1     0    -1    -1    -1    -1     -1  ...        0   \n",
       "1     0     0    -1    -1     0    -1    -1    -1     0     -1  ...        0   \n",
       "2    -1    -1    -1    -1    -1     0     0     0     0      0  ...        0   \n",
       "3     0     0     1    -1    -1    -1     1    -1    -1     -1  ...       -1   \n",
       "4    -1     0     0     0    -1    -1     0    -1     0     -1  ...       -1   \n",
       "\n",
       "   Top17  Top18  Top19  Top20  Top21  Top22  Top23  Top24  Top25  \n",
       "0      0     -1      0      0     -1      0     -1     -1      0  \n",
       "1      0     -1     -1     -1      0      1      0      0      0  \n",
       "2      0      0     -1     -1     -1      0     -1     -1     -1  \n",
       "3      0      0      0      0     -1     -1      0     -1      1  \n",
       "4     -1      0     -1     -1      0     -1     -1      0      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Sentiments.iloc[:,8:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "########################################################\n",
    "# Initial Sentiments\n",
    "########################################################\n",
    "results_KNN = []\n",
    "results_KNN_new_feat = []\n",
    "test_size = 0.2\n",
    "\n",
    "n_n = 5\n",
    "\n",
    "print(20*'===')\n",
    "print(10*' ', 'Initial Sentiments', 10*' ')\n",
    "print(20*'===')\n",
    "\n",
    "##############\n",
    "#Label 1\n",
    "##############\n",
    "y = df_Sentiment_Full.iloc[:, 1]\n",
    "X = df_Sentiment_Full.iloc[:, 8:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "\n",
    "clf = KNN(n_neighbors = n_n)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(5*'===',' Label 1 ', 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "results_KNN.append(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "##############\n",
    "#Label 2\n",
    "##############\n",
    "\n",
    "\n",
    "#Deal wih imbalance\n",
    "for i in range(3):\n",
    "    \n",
    "    df_label2_1= df_Sentiment_Full.sort_values(['2 T = ' + str(threshold_P[i])], ascending = False)\n",
    "    n_pos = df_label2_1.loc[df_label2_1['2 T = ' + str(threshold_P[i])] == 1].shape[0]\n",
    "    df_label2_1 = pd.concat((df_label2_1.iloc[:n_pos, :],df_label2_1.iloc[df_label2_1.shape[0]-n_pos:, :] ))\n",
    "    \n",
    "\n",
    "    y = df_label2_1.iloc[:, i+1]\n",
    "    X = df_label2_1.iloc[:, 8:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "\n",
    "\n",
    "    clf = KNN(n_neighbors = n_n)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(5*'===',' Label 2, threshold', str(threshold_P[i]) , 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "    results_KNN.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.classification_report(y_pred, y_test))\n",
    "\n",
    "###################\n",
    "#Label 3          #\n",
    "###################\n",
    "\n",
    "\n",
    "\n",
    "#Deal wih imbalance\n",
    "for i in range(3):\n",
    "    df_label3_1 = df_Sentiment_Full.sort_values(['3 T = ' + str(threshold_V[i])])\n",
    "    n = df_label3_1.loc[df_label3_1['3 T = ' + str(threshold_V[i])] == -1].shape[0]\n",
    "    df_label3_1 = pd.concat((df_label3_1.iloc[:n, :],df_label3_1.iloc[n +1:2*n, :] ,df_label3_1.iloc[df_label3_1.shape[0]-n:, :] ))\n",
    "\n",
    "\n",
    "    y = df_label3_1.iloc[:, i+5]\n",
    "    X = df_label3_1.iloc[:, 8:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "    \n",
    "    \n",
    "    clf = KNN(n_neighbors = n_n)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(5*'===',' Label 3, threshold ', str(threshold_V[i]), 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "    results_KNN.append(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "########################################################\n",
    "# New features\n",
    "########################################################\n",
    "\n",
    "print('\\n', 20*'===')\n",
    "print(10*' ', 'New Features', 10*' ')\n",
    "print(20*'===')\n",
    "\n",
    "##############\n",
    "#Label 1\n",
    "##############\n",
    "y = df_Sentiments.iloc[:, 1]\n",
    "X = df_Sentiments.iloc[:, 8:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "\n",
    "clf = KNN(n_neighbors = n_n)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(5*'===',' Label 1 ', 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "results_KNN_new_feat.append(metrics.accuracy_score(y_test, y_pred))\n",
    "##############\n",
    "#Label 2\n",
    "##############\n",
    "\n",
    "\n",
    "#Deal wih imbalance\n",
    "for i in range(3):\n",
    "    \n",
    "    df_label2_1= df_Sentiments.sort_values(['2 T = ' + str(threshold_P[i])], ascending = False)\n",
    "    n_pos = df_label2_1.loc[df_label2_1['2 T = ' + str(threshold_P[i])] == 1].shape[0]\n",
    "    df_label2_1 = pd.concat((df_label2_1.iloc[:n_pos, :],df_label2_1.iloc[df_label2_1.shape[0]-n_pos:, :] ))\n",
    "\n",
    "\n",
    "    y = df_label2_1.iloc[:, i+1]\n",
    "    X = df_label2_1.iloc[:, 8:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "\n",
    "    clf = KNN(n_neighbors = n_n)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(5*'===',' Label 2, threshold', str(threshold_P[i]) , 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "    results_KNN_new_feat.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    \n",
    "##############\n",
    "#Label 3\n",
    "##############\n",
    "\n",
    "\n",
    "#Deal wih imbalance\n",
    "for i in range(3):\n",
    "    df_label3_1 = df_Sentiments.sort_values(['3 T = ' + str(threshold_V[i])])\n",
    "    n = df_label3_1.loc[df_label3_1['3 T = ' + str(threshold_V[i])] == -1].shape[0]\n",
    "    df_label3_1 = pd.concat((df_label3_1.iloc[:n, :],df_label3_1.iloc[n +1:2*n, :] ,df_label3_1.iloc[df_label3_1.shape[0]-n:, :] ))\n",
    "\n",
    "\n",
    "    y = df_label3_1.iloc[:, i+5]\n",
    "    X = df_label3_1.iloc[:, 8:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "    \n",
    "    clf = KNN(n_neighbors = n_n)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(5*'===',' Label 3, threshold ', str(threshold_V[i]), 5*'===', '\\n' ,metrics.accuracy_score(y_test, y_pred))\n",
    "    results_KNN_new_feat.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "titles = ['Initial label', 'Price threshold = 0.5%', 'Price threshold = 1%', 'Price threshold = 2%', 'Volume threshold = 0.5%', 'Volume threshold = 1%', 'Volume threshold = 2%']\n",
    "\n",
    "for i in range(7):\n",
    "    plt.bar(['KNN', 'RF', 'SVM'],[results_KNN[i],results_RF[i], results_SVM[i]], color = ['r','g','b'])\n",
    "    plt.xlabel('accuracy score')\n",
    "    plt.ylabel('Models')\n",
    "    plt.title(titles[i])\n",
    "    plt.show()\n",
    "\n",
    "len(results_SVM_new_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "titles = ['Initial label', 'Price threshold = 0.5%', 'Price threshold = 1%', 'Price threshold = 2%', 'Volume threshold = 0.5%', 'Volume threshold = 1%', 'Volume threshold = 2%']\n",
    "\n",
    "for i in range(7):\n",
    "    plt.bar(['KNN', 'RF', 'SVM'],[results_KNN_new_feat[i],results_RF_new_feat[i], results_SVM_new_feat[i]], color = ['r','g','b'])\n",
    "    plt.xlabel('accuracy score')\n",
    "    plt.ylabel('Models')\n",
    "    plt.title(titles[i])\n",
    "    plt.show()\n",
    "\n",
    "len(results_SVM_new_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_ret = []\n",
    "new_feats = np.empty([1985//5,125])\n",
    "\n",
    "for i in range(5, 1985, 5):\n",
    "    if abs((df_DJIA.iloc[i,6]-df_DJIA.iloc[i+5,6])/df_DJIA.iloc[i,6]) > 0.0125:        \n",
    "        week_ret.append(1)\n",
    "    else:\n",
    "        week_ret.append(0)\n",
    "    \n",
    "for i in range(1985//5):\n",
    "    for j in range(125):\n",
    "        if j < 25:\n",
    "            new_feats[i][j] = df_Sentiment_Full.iloc[:,8:].iloc[i*5,j]\n",
    "        elif 25 <= j < 50:\n",
    "            new_feats[i][j] = df_Sentiment_Full.iloc[:,8:].iloc[i*5+1,j-25]\n",
    "        elif 50 <= j < 75:\n",
    "            new_feats[i][j] = df_Sentiment_Full.iloc[:,8:].iloc[i*5+2,j-50]\n",
    "        elif 75 <= j < 100:\n",
    "            new_feats[i][j] = df_Sentiment_Full.iloc[:,8:].iloc[i*5+3,j-75]\n",
    "        else:\n",
    "            new_feats[i][j] = df_Sentiment_Full.iloc[:,8:].iloc[i*5+4,j-100]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 126)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['label']\n",
    "for i in range(125):\n",
    "    col_names.append(i)\n",
    "\n",
    "df_weekly = pd.DataFrame(data = new_feats)\n",
    "df_wlabel = pd.DataFrame(data = week_ret)\n",
    "\n",
    "df_weekly = pd.concat((df_wlabel, df_weekly), axis = 1)\n",
    "df_weekly = df_weekly.fillna(0)\n",
    "df_weekly.columns = col_names\n",
    "\n",
    "df_weekly.head()\n",
    "\n",
    "df_weekly.loc[df_weekly['label']== 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "y = df_weekly.iloc[:, 0]\n",
    "X = df_weekly.iloc[:, 1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3)\n",
    "\n",
    "\n",
    "clf = KNN(n_neighbors = 3)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5083333333333333\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
